# ğŸ“Š Projeto de Engenharia de Dados â€“ Pipeline End-to-End

Este projeto tem como objetivo implementar, na prÃ¡tica, um **pipeline completo de Engenharia de Dados**, seguindo uma arquitetura moderna utilizada no mercado, desde a ingestÃ£o dos dados atÃ© a disponibilizaÃ§Ã£o para consumo analÃ­tico.

O foco principal Ã© **engenharia de dados**, com extensÃµes planejadas para **anÃ¡lise de dados e ciÃªncia de dados**, permitindo uma visÃ£o clara de todo o ciclo de vida dos dados e das responsabilidades de cada etapa.

---

## ğŸ¯ Objetivos do Projeto

- Construir um pipeline de dados **end-to-end**
- Aplicar boas prÃ¡ticas de Engenharia de Dados
- Separar claramente as camadas de dados:
  - ingestÃ£o
  - armazenamento
  - transformaÃ§Ã£o
  - consumo
- Criar um projeto **reprodutÃ­vel**, organizado e adequado para portfÃ³lio

---

## ğŸ§± Arquitetura Geral

Fluxo de dados implementado no projeto:

1Â°- (API + Dados Simulados) (Fontes de Dados)
2Â°- IngestÃ£o (Python)
3Â°- Data Lake (MinIO / S3-like)
4Â°- Staging (Postgres - JSONB)
5Â°- Camada Silver (dbt)
6Â°- Camada Gold (planejada)
7Â°- BI / AnÃ¡lise / CiÃªncia de Dados (planejado)

---

## ğŸ“Œ Fontes de Dados

- **API externa**: dados de produtos (Fake Store API)
- **Dados simulados**:
  - clientes
  - pedidos

Essa combinaÃ§Ã£o simula um cenÃ¡rio realista, integrando:
- dados internos (sistemas transacionais)
- dados externos (APIs de terceiros)

---

## ğŸ—‚ï¸ Camadas de Dados

### [X] Data Lake (Landing / Bronze)
- Armazenamento de dados brutos
- Versionamento por data (`dt=YYYY-MM-DD`)
- Implementado com **MinIO**, simulando um ambiente S3 (AWS)

### [X] Staging
- Banco relacional **PostgreSQL**
- Dados armazenados em formato **JSONB**
- Camada intermediÃ¡ria para flexibilidade, auditoria e reprocessamento

### [ ] Silver
- TransformaÃ§Ãµes realizadas com **dbt**
- Tipagem e normalizaÃ§Ã£o dos dados
- Dados limpos e estruturados, prontos para modelagem analÃ­tica

### [ ] Gold
- Modelo dimensional (Star Schema)
- Tabelas fato e dimensÃµes
- Dados prontos para consumo por BI e anÃ¡lises

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python** â€“ ingestÃ£o e integraÃ§Ã£o de dados
- **Docker & Docker Compose** â€“ infraestrutura local
- **PostgreSQL** â€“ staging e camadas analÃ­ticas
- **MinIO** â€“ Data Lake (S3 local)
- **dbt** â€“ transformaÃ§Ãµes e modelagem analÃ­tica
- **WSL (Linux)** â€“ ambiente de desenvolvimento

---

## âœ… Etapas ConcluÃ­das

- [x] ConfiguraÃ§Ã£o da infraestrutura com Docker
- [x] ImplementaÃ§Ã£o do Data Lake (MinIO)
- [x] Pipeline de ingestÃ£o em Python
- [x] Staging no Postgres com JSONB
- [x] ConfiguraÃ§Ã£o do dbt
- [x] CriaÃ§Ã£o dos primeiros models da camada Silver

---

## ğŸš§ PrÃ³ximas Etapas Planejadas

- [ ] Finalizar camada Silver
- [ ] Criar camada Gold (Star Schema)
- [ ] Implementar testes de qualidade de dados (dbt tests)
- [ ] Orquestrar o pipeline (Airflow ou Prefect)
- [ ] Criar dashboards de BI
- [ ] Realizar anÃ¡lise exploratÃ³ria dos dados
- [ ] ExtensÃ£o para CiÃªncia de Dados (opcional)
